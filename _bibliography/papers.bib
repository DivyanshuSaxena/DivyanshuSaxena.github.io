@misc{DirigoArxiv,
title = {Dirigo: Self-scaling Stateful Actors For Serverless Real-time Data Processing}, 
author = {Le Xu and Divyanshu Saxena and Neeraja J. Yadwadkar and Aditya Akella and Indranil Gupta},
year = {2023},
eprint = {2308.03615},
archivePrefix = {arXiv},
primaryClass = {cs.DC},
abstract = {We propose Dirigo, a distributed stream processing service built atop virtual actors.
Dirigo achieves both a high level of resource efficiency and performance isolation driven
by user intent (SLO). To improve resource efficiency, Dirigo adopts a serverless architecture
that enables time-sharing of compute resources among streaming operators, both within and
across applications. Meanwhile, Dirigo improves performance isolation by inheriting the
property of function autoscaling from serverless architecture. Specifically, Dirigo
proposes (i) dual-mode actor, an actor abstraction that dynamically provides orderliness
guarantee for streaming operator during autoscaling and (ii) a data plane scheduling
mechanism, along with its API, that allows scheduling and scaling at the message-level
granularity.},
url = {https://arxiv.org/abs/2308.03615},
pdf = {https://arxiv.org/pdf/2308.03615.pdf},
abbr = {Arxiv},
format = {Preprint}
}

@inproceedings{AppliedShort,
author = {Divyanshu Saxena and William Zhang and Madhav Tummala and Saksham Goel and Aditya Akella},
title = {Towards Efficient Microservice Communication.},
booktitle = {Proceedings of the 5th Workshop on Advanced Tools, Programming Languages, and PLatforms for Implementing and Evaluating Algorithms for Distributed Systems. Held in conjunction with PODC},
year = {2023},
isbn = {9798400701283},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584684.3597267},
doi = {10.1145/3584684.3597267},
abstract = {Distributed applications on the cloud are being developed
and deployed as microservices as opposed to the monolithic architecture.
Service Meshes have emerged as a way of specifying communication
policies between microservices. Service Meshes have the potential
to abstract the networking requirements of distributed applications
from the application logic. However, current service mesh frameworks
introduce significant performance and resource overheads.
We study the overheads of service meshes and make a case for redesigning
both the control plane and data plane for service meshes.
First, we propose the notion of Application Defined Middleboxes,
which makes it possible for the mesh control planes to reduce the
overheads by optimizing where to implement application policies.
Second, we demonstrate preliminary ideas on accelerating the data
plane to further reduce the overheads.},
articleno = {8},
numpages = {5},
location = {Orlando, FL, USA},
series = {ApPLIED 2023},
pdf = {applied23_short.pdf},
abbr = {ApPLIED '23},
format = {Workshop}
}

@article{OSR23,
author = {Divyanshu Saxena and Tao Ji and Arjun Singhvi and Junaid Khalid and Aditya Akella},
title = {Navigating Performance-Efficiency Tradeoffs in Serverless Computing: Deduplication to the Rescue!},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {1},
issn = {0163-5980},
url = {https://doi.org/10.1145/3606557.3606564},
doi = {10.1145/3606557.3606564},
abstract = {Navigating the performance and efficiency trade-offs is critical for serverless platforms, where the providers ideally want to give the illusion of warm function startups while maintaining low resource costs. Limited controls, provided via toggling sandboxes between warm and cold states and keepalives, force operators to sacrifice significant resources to achieve good performance. We present Medes, a serverless framework, that allows operators to navigate the trade-off space smoothly. Our approach
takes advantage of the high duplication in warm sandboxes
on serverless platforms to develop a new sandbox state, called
a `dedup state', that is more memory-efficient than the warm
state and faster to restore from than the cold state. We use
innovative techniques to identify redundancy with minimal
overhead, and provide a simple management policy to balance performance and memory. Our evaluation demonstrates
that Medes can provide up to 3.8X better end-to-end latencies
and reduce the number of cold starts by 10-50% against the
state-of-the-art baselines.},
journal = {SIGOPS Operating Systems Review},
month = {jun},
pages = {47-53},
numpages = {7},
pdf = {osr23.pdf},
abbr = {ACM OSR '23},
format = {Journal},
}

@inproceedings{Medes,
author = {Divyanshu Saxena and Tao Ji and Arjun Singhvi and Junaid Khalid and Aditya Akella},
title = {Memory Deduplication for Serverless Computing with Medes.},
booktitle={Proceedings of the Seventeenth European Conference on Computer Systems},
year = {2022},
isbn = {9781450391627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Serverless platforms today impose rigid trade-offs between
resource use and user-perceived performance. Limited controls, provided via toggling sandboxes between warm and
cold states and keep-alives, force operators to sacrifice significant resources to achieve good performance. We present a
serverless framework, Medes, that breaks the rigid trade-off
and allows operators to navigate the trade-off space smoothly.
Medes leverages the fact that the warm sandboxes running
on serverless platforms have a high fraction of duplication in
their memory footprints. We exploit these redundant chunks
to develop a new sandbox state, called a dedup state, that
is more memory-efficient than the warm state and faster to
restore from than the cold state. We develop novel mechanisms to identify memory redundancy at minimal overhead
while ensuring that the dedup containers' memory footprint
is small. Finally, we develop a simple sandbox management
policy that exposes a narrow, intuitive interface for operators
to trade-off performance for memory by jointly controlling
warm and dedup sandboxes. Detailed experiments with a
protoformat using real-world serverless workloads demonstrate
that Medes can provide up to 1X-2.75X improvements in the
end-to-end latencies. The benefits of Medes are enhanced in
memory pressure situations, where Medes can provide up to
3.8X improvements in end-to-end latencies. Medes achieves
this by reducing the number of cold starts incurred by 10-50%
against the state-of-the-art baselines.},
url = {https://doi.org/10.1145/3492321.3524272},
code = {https://github.com/DivyanshuSaxena/Medes},
pdf = {medes.pdf},
doi = {10.1145/3492321.3524272},
location = {Rennes, France},
abbr = {EuroSys '22},
format = {Conference}
}

@inproceedings{NSDIPoster,
author = {Divyanshu Saxena and Saksham Goel and William Zhang and Madhav Tummala and Aditya Akella},
title = {Application-tailored Communication with xMesh.},
booktitle={NSDI '23: 20th USENIX Symposium on Networked Systems Design and Implementation},
year = {2023},
location = {Boston, MA},
abbr = {NSDI '23},
format = {Poster}
}
